{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Lane Lines Project\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define findLaneLines function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findLaneLines(image):\n",
    "    #Define Parameters\n",
    "    #------------------------------------\n",
    "    #Region mask Parameters\n",
    "    lowery=1\n",
    "    upppery=0.55\n",
    "    dx=0.07\n",
    "    gap=0.04\n",
    "    #Color mask parameters\n",
    "    white_threshold=np.array([175],dtype=\"uint8\")\n",
    "    yellow_threshold=np.array([50, 0, 150],dtype=\"uint8\")\n",
    "    upperb_white=np.array([255],dtype=\"uint8\")\n",
    "    upperb_yellow=np.array([255,150,255],dtype=\"uint8\")\n",
    "    #Gaussian smoothing kernel\n",
    "    kernel_size = 5\n",
    "    #Canny edge detection thresholds\n",
    "    low_threshold = 50\n",
    "    high_threshold = 180\n",
    "    #Hough lines parameters\n",
    "    rho = 1 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 5     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 15 #minimum number of pixels making up a line\n",
    "    max_line_gap = 15    # maximum gap in pixels between connectable line segments\n",
    "    #threshold to determine if line is yellow\n",
    "    minYellow=300\n",
    "    #-------------------------------------\n",
    "    \n",
    "    #Convert BGR image to lab color space and gray scale\n",
    "    lab = cv2.cvtColor(image,cv2.COLOR_BGR2LAB)\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    #Calculate yellow and white color masks\n",
    "    white_mask=cv2.inRange(gray,white_threshold,upperb_white)\n",
    "    yellow_mask=cv2.inRange(lab,yellow_threshold,upperb_yellow)\n",
    "    #Smoothe gray scale image\n",
    "    blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n",
    "    #normalize B channel of lab image\n",
    "    normalizedImg=cv2.normalize(lab[:,:,2],np.zeros_like(lab[:,:,2]), 0, 255, cv2.NORM_MINMAX)\n",
    "    #Extract edges from gray scale LAB color space images and merge them\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "    edges=cv2.bitwise_or(cv2.Canny(normalizedImg, 30, 180),edges)\n",
    "    #Filter edges with color masks\n",
    "    white_edges=cv2.bitwise_and(edges,edges,mask=white_mask)\n",
    "    yellow_edges=cv2.bitwise_and(edges,edges,mask=yellow_mask)\n",
    "    #Create regional masks, for areas whare lane lines are expected\n",
    "    left_mask = np.zeros_like(edges)\n",
    "    right_mask = np.zeros_like(edges)\n",
    "    ignore_mask_color = 255   \n",
    "    #define corners\n",
    "    ysize = image.shape[0]\n",
    "    xsize = image.shape[1]\n",
    "    \n",
    "    left_left_top=[xsize*(0.5-dx),ysize*upppery]\n",
    "    left_right_top=[xsize*(0.50-gap),ysize*upppery]\n",
    "    left_left_bottom=[xsize*dx,ysize*lowery]\n",
    "    left_right_bottom=[xsize*(0.5-2*gap),ysize*lowery]\n",
    "    \n",
    "    right_left_top=[xsize*(0.5+gap),ysize*upppery]\n",
    "    right_right_top=[xsize*(0.5+dx),ysize*upppery]\n",
    "    right_left_bottom=[xsize*(0.5+2*gap),ysize*lowery]\n",
    "    right_right_bottom=[xsize*(1-dx),ysize*lowery]\n",
    "    #Create polygons from corners\n",
    "    left_vertices = np.array([[left_left_top,left_right_top, left_right_bottom, left_left_bottom]], dtype=np.int32)\n",
    "    right_vertices = np.array([[right_left_top,right_right_top, right_right_bottom, right_left_bottom]], dtype=np.int32)\n",
    "    #Set marks as areas within the polygons\n",
    "    cv2.fillPoly(left_mask, left_vertices, ignore_mask_color)\n",
    "    cv2.fillPoly(right_mask, right_vertices, ignore_mask_color)\n",
    "    #check if lane lines are white or yellow\n",
    "    countYellowLeft=cv2.countNonZero(cv2.bitwise_and(yellow_mask, left_mask))\n",
    "    countYellowRight=cv2.countNonZero(cv2.bitwise_and(yellow_mask, right_mask))\n",
    "    left_yellow=(countYellowLeft>minYellow)\n",
    "    #print(\"Left: Yellow Count: \", countYellowLeft)\n",
    "    right_yellow=(countYellowRight>minYellow)\n",
    "    #print(\"Right Yellow Count: \", countYellowRight)\n",
    "    if(left_yellow):\n",
    "        left_masked_edges = cv2.bitwise_and(yellow_edges, left_mask)\n",
    "    else:\n",
    "        left_masked_edges = cv2.bitwise_and(white_edges, left_mask)\n",
    "    if(right_yellow):\n",
    "        right_masked_edges = cv2.bitwise_and(yellow_edges, right_mask)\n",
    "    else:\n",
    "        right_masked_edges = cv2.bitwise_and(white_edges, right_mask)\n",
    "    \n",
    "    line_image = np.copy(image)*0 # creating a blank to draw lines on\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    left_lines = cv2.HoughLinesP(left_masked_edges, rho, theta, threshold, np.array([]),\n",
    "                                    min_line_length, max_line_gap)\n",
    "    right_lines = cv2.HoughLinesP(right_masked_edges, rho, theta, threshold, np.array([]),\n",
    "                                    min_line_length, max_line_gap)\n",
    "    # Iterate over the output \"lines\" and draw lines on a blank image\n",
    "    x=[]\n",
    "    y=[]\n",
    "    if(left_lines is None):\n",
    "        print(\"No left_lines detected! Yellow: \"+str(left_yellow))\n",
    "    else:\n",
    "        #Extract X and Y values from hough lines\n",
    "        for line in left_lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                x.append(x1)\n",
    "                y.append(y1)\n",
    "                x.append(x2)\n",
    "                y.append(y2)\n",
    "        #try fitting a 2nd degree polynomial\n",
    "        poly=np.polyfit(y,x,2)\n",
    "        #if rank is low fit a 1st gegree polynomial\n",
    "        if(np.ndim(poly)<2):\n",
    "            poly=np.polyfit(y,x,1)\n",
    "            p = np.poly1d(poly)\n",
    "        #calculate points along the poly in 10px steps\n",
    "        y = np.arange(ysize*upppery, ysize*(lowery), 10)\n",
    "        y = np.arange(ysize*upppery, ysize*(lowery), 10)\n",
    "        x=p(y)\n",
    "        i=0\n",
    "        #draw lines\n",
    "        for xi in x:\n",
    "            cv2.line(line_image,(int(round(xi)),int(round(y[i]))),(int(round(x[i+1])),int(round(y[i+1]))),(255,0,0),10)\n",
    "            i=i+1\n",
    "            if i+1==len(x):\n",
    "                break\n",
    "    #Do the same for the right side\n",
    "    x=[]\n",
    "    y=[]\n",
    "    if(right_lines is None):\n",
    "        print(\"No right_lines detected! Yellow: \"+str(right_yellow))\n",
    "    else:\n",
    "        \n",
    "        for line in right_lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                #if((abs(x1-x2))<(100*abs(y1-y2))):\n",
    "                x.append(x1)\n",
    "                y.append(y1)\n",
    "                x.append(x2)\n",
    "                y.append(y2)\n",
    "        poly=np.polyfit(y,x,2)\n",
    "        if(np.ndim(poly)<2):\n",
    "            poly=np.polyfit(y,x,1)\n",
    "            p = np.poly1d(poly)\n",
    "        y = np.arange(ysize*upppery, ysize*(lowery), 10)\n",
    "        y = np.arange(ysize*upppery, ysize*(lowery), 10)\n",
    "        x=p(y)\n",
    "        i=0\n",
    "        for xi in x:\n",
    "            cv2.line(line_image,(int(round(xi)),int(round(y[i]))),(int(round(x[i+1])),int(round(y[i+1]))),(0,0,255),10)\n",
    "            i=i+1\n",
    "            if i+1==len(x):\n",
    "                break\n",
    "\n",
    "    # Draw the lines on the original image\n",
    "\n",
    "    lines_edges = cv2.addWeighted(image, 0.8, line_image, 1, 0) \n",
    "    return lines_edges;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input video and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening video: challenge.mp4\n",
      "processing Frame  0\n",
      "processing Frame  1\n",
      "processing Frame  2\n",
      "processing Frame  3\n",
      "processing Frame  4\n",
      "processing Frame  5\n",
      "processing Frame  6\n",
      "processing Frame  7\n",
      "processing Frame  8\n",
      "processing Frame  9\n",
      "processing Frame  10\n",
      "processing Frame  11\n",
      "processing Frame  12\n",
      "processing Frame  13\n",
      "processing Frame  14\n",
      "processing Frame  15\n",
      "processing Frame  16\n",
      "processing Frame  17\n",
      "processing Frame  18\n",
      "processing Frame  19\n",
      "processing Frame  20\n",
      "processing Frame  21\n",
      "processing Frame  22\n",
      "processing Frame  23\n",
      "processing Frame  24\n",
      "processing Frame  25\n",
      "processing Frame  26\n",
      "processing Frame  27\n",
      "processing Frame  28\n",
      "processing Frame  29\n",
      "processing Frame  30\n",
      "processing Frame  31\n",
      "processing Frame  32\n",
      "processing Frame  33\n",
      "processing Frame  34\n",
      "processing Frame  35\n",
      "processing Frame  36\n",
      "processing Frame  37\n",
      "processing Frame  38\n",
      "processing Frame  39\n",
      "processing Frame  40\n",
      "processing Frame  41\n",
      "processing Frame  42\n",
      "processing Frame  43\n",
      "processing Frame  44\n",
      "processing Frame  45\n",
      "processing Frame  46\n",
      "processing Frame  47\n",
      "processing Frame  48\n",
      "processing Frame  49\n",
      "processing Frame  50\n",
      "processing Frame  51\n",
      "processing Frame  52\n",
      "processing Frame  53\n",
      "processing Frame  54\n",
      "processing Frame  55\n",
      "processing Frame  56\n",
      "processing Frame  57\n",
      "processing Frame  58\n",
      "processing Frame  59\n",
      "processing Frame  60\n",
      "processing Frame  61\n",
      "processing Frame  62\n",
      "processing Frame  63\n",
      "processing Frame  64\n",
      "processing Frame  65\n",
      "processing Frame  66\n",
      "processing Frame  67\n",
      "processing Frame  68\n",
      "processing Frame  69\n",
      "processing Frame  70\n",
      "processing Frame  71\n",
      "processing Frame  72\n",
      "processing Frame  73\n",
      "processing Frame  74\n",
      "processing Frame  75\n",
      "processing Frame  76\n",
      "processing Frame  77\n",
      "processing Frame  78\n",
      "processing Frame  79\n",
      "processing Frame  80\n",
      "processing Frame  81\n",
      "processing Frame  82\n",
      "processing Frame  83\n",
      "processing Frame  84\n",
      "processing Frame  85\n",
      "processing Frame  86\n",
      "processing Frame  87\n",
      "processing Frame  88\n",
      "processing Frame  89\n",
      "processing Frame  90\n",
      "processing Frame  91\n",
      "processing Frame  92\n",
      "processing Frame  93\n",
      "processing Frame  94\n",
      "processing Frame  95\n",
      "processing Frame  96\n",
      "processing Frame  97\n",
      "processing Frame  98\n",
      "processing Frame  99\n",
      "processing Frame  100\n",
      "processing Frame  101\n",
      "processing Frame  102\n",
      "processing Frame  103\n",
      "processing Frame  104\n",
      "processing Frame  105\n",
      "processing Frame  106\n",
      "processing Frame  107\n",
      "processing Frame  108\n",
      "processing Frame  109\n",
      "processing Frame  110\n",
      "processing Frame  111\n",
      "processing Frame  112\n",
      "processing Frame  113\n",
      "processing Frame  114\n",
      "processing Frame  115\n",
      "processing Frame  116\n",
      "processing Frame  117\n",
      "processing Frame  118\n",
      "processing Frame  119\n",
      "processing Frame  120\n",
      "processing Frame  121\n",
      "processing Frame  122\n",
      "processing Frame  123\n",
      "processing Frame  124\n",
      "processing Frame  125\n",
      "processing Frame  126\n",
      "processing Frame  127\n",
      "processing Frame  128\n",
      "processing Frame  129\n",
      "processing Frame  130\n",
      "processing Frame  131\n",
      "processing Frame  132\n",
      "processing Frame  133\n",
      "processing Frame  134\n",
      "processing Frame  135\n",
      "processing Frame  136\n",
      "processing Frame  137\n",
      "processing Frame  138\n",
      "processing Frame  139\n",
      "processing Frame  140\n",
      "processing Frame  141\n",
      "processing Frame  142\n",
      "processing Frame  143\n",
      "processing Frame  144\n",
      "processing Frame  145\n",
      "processing Frame  146\n",
      "processing Frame  147\n",
      "processing Frame  148\n",
      "processing Frame  149\n",
      "processing Frame  150\n",
      "processing Frame  151\n",
      "processing Frame  152\n",
      "processing Frame  153\n",
      "processing Frame  154\n",
      "processing Frame  155\n",
      "processing Frame  156\n",
      "processing Frame  157\n",
      "processing Frame  158\n",
      "processing Frame  159\n",
      "processing Frame  160\n",
      "processing Frame  161\n",
      "processing Frame  162\n",
      "processing Frame  163\n",
      "processing Frame  164\n",
      "processing Frame  165\n",
      "processing Frame  166\n",
      "processing Frame  167\n",
      "processing Frame  168\n",
      "processing Frame  169\n",
      "processing Frame  170\n",
      "processing Frame  171\n",
      "processing Frame  172\n",
      "processing Frame  173\n",
      "processing Frame  174\n",
      "processing Frame  175\n",
      "processing Frame  176\n",
      "processing Frame  177\n",
      "processing Frame  178\n",
      "processing Frame  179\n",
      "processing Frame  180\n",
      "processing Frame  181\n",
      "processing Frame  182\n",
      "processing Frame  183\n",
      "processing Frame  184\n",
      "processing Frame  185\n",
      "processing Frame  186\n",
      "processing Frame  187\n",
      "processing Frame  188\n",
      "processing Frame  189\n",
      "processing Frame  190\n",
      "processing Frame  191\n",
      "processing Frame  192\n",
      "processing Frame  193\n",
      "processing Frame  194\n",
      "processing Frame  195\n",
      "processing Frame  196\n",
      "processing Frame  197\n",
      "processing Frame  198\n",
      "processing Frame  199\n",
      "processing Frame  200\n",
      "processing Frame  201\n",
      "processing Frame  202\n",
      "processing Frame  203\n",
      "processing Frame  204\n",
      "processing Frame  205\n",
      "processing Frame  206\n",
      "processing Frame  207\n",
      "processing Frame  208\n",
      "processing Frame  209\n",
      "processing Frame  210\n",
      "processing Frame  211\n",
      "processing Frame  212\n",
      "processing Frame  213\n",
      "processing Frame  214\n",
      "processing Frame  215\n",
      "processing Frame  216\n",
      "processing Frame  217\n",
      "processing Frame  218\n",
      "processing Frame  219\n",
      "processing Frame  220\n",
      "processing Frame  221\n",
      "processing Frame  222\n",
      "processing Frame  223\n",
      "processing Frame  224\n",
      "processing Frame  225\n",
      "processing Frame  226\n",
      "processing Frame  227\n",
      "processing Frame  228\n",
      "processing Frame  229\n",
      "processing Frame  230\n",
      "processing Frame  231\n",
      "processing Frame  232\n",
      "processing Frame  233\n",
      "processing Frame  234\n",
      "processing Frame  235\n",
      "processing Frame  236\n",
      "processing Frame  237\n",
      "processing Frame  238\n",
      "processing Frame  239\n",
      "processing Frame  240\n",
      "processing Frame  241\n",
      "processing Frame  242\n",
      "processing Frame  243\n"
     ]
    }
   ],
   "source": [
    "video = \"challenge.mp4\"\n",
    "#video=\"solidYellowLeft.mp4\"\n",
    "#video=\"solidWhiteRight.mp4\"\n",
    "fps=24\n",
    "fourcc = cv2.VideoWriter_fourcc('a', 'v', 'c', '1') \n",
    "init=bool(1)\n",
    "print(\"opening video: \"+video)\n",
    "vidcap = cv2.VideoCapture(video)\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "success = True\n",
    "while success:\n",
    "    success,image = vidcap.read()\n",
    "    print(\"processing Frame \", count)\n",
    "    count=count+1\n",
    "    if (init):\n",
    "        shape=image.shape\n",
    "        writer = cv2.VideoWriter(video.replace(\".mp4\",\"_processed.mp4\"),fourcc, fps, (image.shape[1],image.shape[0]))\n",
    "        init=bool(0)\n",
    "    if (success):\n",
    "        writer.write(findLaneLines(image))\n",
    "    else:\n",
    "        writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=1280 height=720 controls>\n",
       "  <source src=\"challenge_processed.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width=str(shape[1])\n",
    "height=str(shape[0])\n",
    "HTML(\"\"\"\n",
    "<video width=\"\"\"+width+\"\"\" height=\"\"\"+height+\"\"\" controls>\n",
    "  <source src=\"{0}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video.replace(\".mp4\",\"_processed.mp4\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'540'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'960'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
